{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use word embeddings to determine bias?\n",
    "Word embeddings are a way to represent words as vectors in a high-dimensional space allowing us to perform mathematical operations on them. For example, we can find the vector that represents the word “king” and the vector that represents the word “queen” and then find the vector that represents the word “man” and add it to the vector that represents the difference between \"king\" and \"queen\" to get the vector that represents the word \"women”. This is a very powerful way to represent words and their relationships to each other. \n",
    "\n",
    "However, sometimes one group is closer to words that represents toxic or bad intentions. Hence, we will try to find the distances between the clusters that represent a cultural group and the clusters that represent toxic words. And look at the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting pytorch_transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "     |████████████████████████████████| 176 kB 4.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (2.26.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (1.9.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (4.62.3)\n",
      "Requirement already satisfied: regex in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (2021.9.30)\n",
      "Requirement already satisfied: boto3 in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (1.24.84)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (1.22.3)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp39-cp39-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Requirement already satisfied: sacremoses in /opt/homebrew/lib/python3.9/site-packages (from pytorch_transformers) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.9/site-packages (from torch>=1.0.0->pytorch_transformers) (3.10.0.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/lib/python3.9/site-packages (from boto3->pytorch_transformers) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.84 in /opt/homebrew/lib/python3.9/site-packages (from boto3->pytorch_transformers) (1.27.84)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/homebrew/lib/python3.9/site-packages (from boto3->pytorch_transformers) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests->pytorch_transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests->pytorch_transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from requests->pytorch_transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests->pytorch_transformers) (3.3)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.9/site-packages (from sacremoses->pytorch_transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.9/site-packages (from sacremoses->pytorch_transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/homebrew/lib/python3.9/site-packages (from sacremoses->pytorch_transformers) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/homebrew/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.84->boto3->pytorch_transformers) (2.8.2)\n",
      "Installing collected packages: sentencepiece, pytorch-transformers\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed pytorch-transformers-1.2.0 sentencepiece-0.1.97\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "here          2,182\n",
      "is            2,003\n",
      "the           1,996\n",
      "sentence      6,251\n",
      "i             1,045\n",
      "want          2,215\n",
      "em            7,861\n",
      "##bed         8,270\n",
      "##ding        4,667\n",
      "##s           2,015\n",
      "for           2,005\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "## Load pretrained model/tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define an input text\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the cluster of words that represent toxic words\n",
    "import torch\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
