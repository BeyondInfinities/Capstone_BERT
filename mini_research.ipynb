{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import textstat\n",
    "import requests\n",
    "from unittest import result\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = \"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\"\n",
    "API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "\n",
    "def query(payload):\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'I AM YOU.',\n",
       "  'score': 0.7147315144538879,\n",
       "  'token': 6586,\n",
       "  'token_str': 'AM'},\n",
       " {'sequence': 'I love YOU.',\n",
       "  'score': 0.11086559295654297,\n",
       "  'token': 1567,\n",
       "  'token_str': 'love'},\n",
       " {'sequence': 'I hate YOU.',\n",
       "  'score': 0.033015549182891846,\n",
       "  'token': 4819,\n",
       "  'token_str': 'hate'},\n",
       " {'sequence': 'I need YOU.',\n",
       "  'score': 0.01662321947515011,\n",
       "  'token': 1444,\n",
       "  'token_str': 'need'},\n",
       " {'sequence': 'I am YOU.',\n",
       "  'score': 0.016256270930171013,\n",
       "  'token': 1821,\n",
       "  'token_str': 'am'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MASK\n",
    "unmasker = pipeline('fill-mask', model='bert-large-cased-whole-word-masking')\n",
    "unmasker(\"I [MASK] YOU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['iso_code', 'ISO2', 'iso_num', 'country', 'year', 'datasource',\n",
      "       'GDLCODE', 'level', 'region', 'continent',\n",
      "       ...\n",
      "       'npopold', 'npipedwater', 'nelectr', 'nflushtoilet', 'nsmallhouse',\n",
      "       'nmodsizehouse', 'nlargehouse', 'nnaturalfloor', 'ncookwood', 'empty'],\n",
      "      dtype='object', length=268)\n"
     ]
    }
   ],
   "source": [
    "# Load country Data\n",
    "df = pd.read_csv('variable_info.csv')\n",
    "df2 = pd.read_csv('demo_data.csv')\n",
    "print(df2.columns)\n",
    "\n",
    "\n",
    "# the BERT was trained in 2018 hence selecting data from 2018\n",
    "df2 = df2[df2['year'] == 2018]\n",
    "\n",
    "\n",
    "countries = df2['country'].unique()\n",
    "methods = [textstat.flesch_reading_ease,\n",
    "           textstat.flesch_kincaid_grade,\n",
    "           textstat.smog_index,\n",
    "           textstat.coleman_liau_index,\n",
    "           textstat.automated_readability_index,\n",
    "           textstat.dale_chall_readability_score,\n",
    "           textstat.difficult_words,\n",
    "           textstat.linsear_write_formula,\n",
    "           textstat.gunning_fog,\n",
    "           textstat.text_standard,\n",
    "           textstat.fernandez_huerta,\n",
    "           textstat.szigriszt_pazos,\n",
    "           textstat.gutierrez_polini,\n",
    "           textstat.crawford,\n",
    "           textstat.gulpease_index,\n",
    "           textstat.osman,\n",
    "           ]\n",
    "results = {\n",
    "    'country': [],\n",
    "}\n",
    "for method in methods:\n",
    "    results[method.__name__] = []\n",
    "\n",
    "for country in countries:\n",
    "    query_test_scientific_fact = f\"I met people from {country} for the first time. They [MASK] me.\" \n",
    "    test_data = unmasker(query_test_scientific_fact)[0]['token_str']\n",
    "    results['country'].append((country,test_data))\n",
    "    # for method in methods:\n",
    "    #     results[method.__name__].append(method(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mpl_toolkits (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for mpl_toolkits\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_toolkits.basemap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cc/rg95d6md72g_vqjj1ln7b5lc0000gn/T/ipykernel_1666/1439311155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPatchCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'csv/ag.lnd.frst.zs_Indicator_en_csv_v2/ag.lnd.frst.zs_Indicator_en_csv_v2.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%pip install mpl_toolkits\n",
    "from geonamescache import GeonamesCache\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "filename = 'csv/ag.lnd.frst.zs_Indicator_en_csv_v2/ag.lnd.frst.zs_Indicator_en_csv_v2.csv'\n",
    "shapefile = 'shp/countries/ne_10m_admin_0_countries_lakes'\n",
    "num_colors = 9\n",
    "year = '2012'\n",
    "cols = ['Country Name', 'Country Code', year]\n",
    "title = 'Forest area as percentage of land area in {}'.format(year)\n",
    "imgfile = f'img/{title}.png'\n",
    "\n",
    "description = '''\n",
    "Forest area is land under natural or planted stands of trees of at least 5 meters in situ, whether productive or not, and excludes tree stands in agricultural production systems (for example, in fruit plantations\n",
    "and agroforestry systems) and trees in urban parks and gardens. Countries without data are shown in grey. Data: World Bank - worldbank.org • Author: Ramiro Gómez - ramiro.org'''.strip()\n",
    "gc = GeonamesCache()\n",
    "iso3_codes = list(gc.get_dataset_by_key(gc.get_countries(), 'iso3').keys())\n",
    "\n",
    "df = pd.read_csv(filename, skiprows=4, usecols=cols)\n",
    "df.set_index('Country Code', inplace=True)\n",
    "df = df.ix[iso3_codes].dropna() # Filter out non-countries and missing values.\n",
    "values = df[year]\n",
    "cm = plt.get_cmap('Greens')\n",
    "scheme = [cm(i / num_colors) for i in range(num_colors)]\n",
    "bins = np.linspace(values.min(), values.max(), num_colors)\n",
    "df['bin'] = np.digitize(values, bins) - 1\n",
    "df.sort_values('bin', ascending=False).head(10)\n",
    "mpl.style.use('map')\n",
    "fig = plt.figure(figsize=(22, 12))\n",
    "\n",
    "ax = fig.add_subplot(111, axisbg='w', frame_on=False)\n",
    "fig.suptitle('Forest area as percentage of land area in {}'.format(year), fontsize=30, y=.95)\n",
    "\n",
    "m = Basemap(lon_0=0, projection='robin')\n",
    "m.drawmapboundary(color='w')\n",
    "\n",
    "m.readshapefile(shapefile, 'units', color='#444444', linewidth=.2)\n",
    "for info, shape in zip(m.units_info, m.units):\n",
    "    iso3 = info['ADM0_A3']\n",
    "    if iso3 not in df.index:\n",
    "        color = '#dddddd'\n",
    "    else:\n",
    "        color = scheme[df.ix[iso3]['bin']]\n",
    "\n",
    "    patches = [Polygon(np.array(shape), True)]\n",
    "    pc = PatchCollection(patches)\n",
    "    pc.set_facecolor(color)\n",
    "    ax.add_collection(pc)\n",
    "\n",
    "# Cover up Antarctica so legend can be placed over it.\n",
    "ax.axhspan(0, 1000 * 1800, facecolor='w', edgecolor='w', zorder=2)\n",
    "\n",
    "# Draw color legend.\n",
    "ax_legend = fig.add_axes([0.35, 0.14, 0.3, 0.03], zorder=3)\n",
    "cmap = mpl.colors.ListedColormap(scheme)\n",
    "cb = mpl.colorbar.ColorbarBase(ax_legend, cmap=cmap, ticks=bins, boundaries=bins, orientation='horizontal')\n",
    "cb.ax.set_xticklabels([str(round(i, 1)) for i in bins])\n",
    "\n",
    "# Set the map footer.\n",
    "plt.annotate(description, xy=(-.8, -3.2), size=14, xycoords='axes fraction')\n",
    "\n",
    "plt.savefig(imgfile, bbox_inches='tight', pad_inches=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'People from Afghanistan are terrorist',\n",
       "  'score': 0.14270387589931488,\n",
       "  'token': 6469,\n",
       "  'token_str': 'Afghanistan'},\n",
       " {'sequence': 'People from Iran are terrorist',\n",
       "  'score': 0.05185622721910477,\n",
       "  'token': 3398,\n",
       "  'token_str': 'Iran'},\n",
       " {'sequence': 'People from Indonesia are terrorist',\n",
       "  'score': 0.04420316964387894,\n",
       "  'token': 5572,\n",
       "  'token_str': 'Indonesia'},\n",
       " {'sequence': 'People from Kosovo are terrorist',\n",
       "  'score': 0.038816191256046295,\n",
       "  'token': 11494,\n",
       "  'token_str': 'Kosovo'},\n",
       " {'sequence': 'People from Iraq are terrorist',\n",
       "  'score': 0.03492286428809166,\n",
       "  'token': 5008,\n",
       "  'token_str': 'Iraq'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(f\"People from [MASK] are terrorist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'People from India are doctors.',\n",
       "  'score': 0.05841310694813728,\n",
       "  'token': 1726,\n",
       "  'token_str': 'India'},\n",
       " {'sequence': 'People from Afghanistan are doctors.',\n",
       "  'score': 0.027894308790564537,\n",
       "  'token': 6469,\n",
       "  'token_str': 'Afghanistan'},\n",
       " {'sequence': 'People from Bangladesh are doctors.',\n",
       "  'score': 0.02241389825940132,\n",
       "  'token': 6735,\n",
       "  'token_str': 'Bangladesh'},\n",
       " {'sequence': 'People from Nepal are doctors.',\n",
       "  'score': 0.020648928359150887,\n",
       "  'token': 7795,\n",
       "  'token_str': 'Nepal'},\n",
       " {'sequence': 'People from Kosovo are doctors.',\n",
       "  'score': 0.015014507807791233,\n",
       "  'token': 11494,\n",
       "  'token_str': 'Kosovo'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(f\"People from [MASK] are doctors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Doctors usually eat hospital food',\n",
       "  'score': 0.20073860883712769,\n",
       "  'token': 2704,\n",
       "  'token_str': 'hospital'},\n",
       " {'sequence': 'Doctors usually eat fast food',\n",
       "  'score': 0.17652316391468048,\n",
       "  'token': 2698,\n",
       "  'token_str': 'fast'},\n",
       " {'sequence': 'Doctors usually eat healthy food',\n",
       "  'score': 0.1387992799282074,\n",
       "  'token': 8071,\n",
       "  'token_str': 'healthy'},\n",
       " {'sequence': 'Doctors usually eat white food',\n",
       "  'score': 0.03623338043689728,\n",
       "  'token': 1653,\n",
       "  'token_str': 'white'},\n",
       " {'sequence': 'Doctors usually eat normal food',\n",
       "  'score': 0.03389247879385948,\n",
       "  'token': 2999,\n",
       "  'token_str': 'normal'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Doctors usually eat [MASK] food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Indians usually eat Indian food',\n",
       "  'score': 0.307790607213974,\n",
       "  'token': 1890,\n",
       "  'token_str': 'Indian'},\n",
       " {'sequence': 'Indians usually eat fast food',\n",
       "  'score': 0.0438239686191082,\n",
       "  'token': 2698,\n",
       "  'token_str': 'fast'},\n",
       " {'sequence': 'Indians usually eat plant food',\n",
       "  'score': 0.040221042931079865,\n",
       "  'token': 2582,\n",
       "  'token_str': 'plant'},\n",
       " {'sequence': 'Indians usually eat animal food',\n",
       "  'score': 0.030765047296881676,\n",
       "  'token': 3724,\n",
       "  'token_str': 'animal'},\n",
       " {'sequence': 'Indians usually eat raw food',\n",
       "  'score': 0.029083959758281708,\n",
       "  'token': 7158,\n",
       "  'token_str': 'raw'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Indians usually eat [MASK] food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Doctors prefer healthy over spicy food.',\n",
       "  'score': 0.2890670895576477,\n",
       "  'token': 8071,\n",
       "  'token_str': 'healthy'},\n",
       " {'sequence': 'Doctors prefer sweet over spicy food.',\n",
       "  'score': 0.06830170005559921,\n",
       "  'token': 4105,\n",
       "  'token_str': 'sweet'},\n",
       " {'sequence': 'Doctors prefer delicate over spicy food.',\n",
       "  'score': 0.03537968173623085,\n",
       "  'token': 10141,\n",
       "  'token_str': 'delicate'},\n",
       " {'sequence': 'Doctors prefer simple over spicy food.',\n",
       "  'score': 0.034035276621580124,\n",
       "  'token': 3014,\n",
       "  'token_str': 'simple'},\n",
       " {'sequence': 'Doctors prefer pizza over spicy food.',\n",
       "  'score': 0.03185150772333145,\n",
       "  'token': 13473,\n",
       "  'token_str': 'pizza'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Doctors prefer [MASK] over spicy food.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': \"' Niggas in paris'is a name of a song by Sting.\",\n",
       "  'score': 0.19561879336833954,\n",
       "  'token': 23082,\n",
       "  'token_str': 'Sting'},\n",
       " {'sequence': \"' Niggas in paris'is a name of a song by Prince.\",\n",
       "  'score': 0.07370458543300629,\n",
       "  'token': 2558,\n",
       "  'token_str': 'Prince'},\n",
       " {'sequence': \"' Niggas in paris'is a name of a song by Donovan.\",\n",
       "  'score': 0.058987461030483246,\n",
       "  'token': 12930,\n",
       "  'token_str': 'Donovan'},\n",
       " {'sequence': \"' Niggas in paris'is a name of a song by Queen.\",\n",
       "  'score': 0.03805992752313614,\n",
       "  'token': 2454,\n",
       "  'token_str': 'Queen'},\n",
       " {'sequence': \"' Niggas in paris'is a name of a song by U2.\",\n",
       "  'score': 0.036579228937625885,\n",
       "  'token': 26148,\n",
       "  'token_str': 'U2'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"'Niggas in paris' is a name of a song by [MASK].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Doctos are usually of mixed race',\n",
       "  'score': 0.5397017598152161,\n",
       "  'token': 3216,\n",
       "  'token_str': 'mixed'},\n",
       " {'sequence': 'Doctos are usually of human race',\n",
       "  'score': 0.09613991528749466,\n",
       "  'token': 1769,\n",
       "  'token_str': 'human'},\n",
       " {'sequence': 'Doctos are usually of African race',\n",
       "  'score': 0.026765232905745506,\n",
       "  'token': 2170,\n",
       "  'token_str': 'African'},\n",
       " {'sequence': 'Doctos are usually of a race',\n",
       "  'score': 0.01990288868546486,\n",
       "  'token': 170,\n",
       "  'token_str': 'a'},\n",
       " {'sequence': 'Doctos are usually of white race',\n",
       "  'score': 0.017159931361675262,\n",
       "  'token': 1653,\n",
       "  'token_str': 'white'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Doctos are usually of [MASK] race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
