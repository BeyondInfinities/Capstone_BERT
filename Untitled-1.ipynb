{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a feedforward Neural\n",
    "# network model that takes in a 2000 x 1 vector of numbers and outputs a 1 x 2 vector of numbers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# The way we would like train this model is to increase one layer of neurons after every epoch till it reaches \n",
    "# a certain accuracy.\n",
    "\n",
    "\n",
    "X = np.linspace(-1, 1, 2000)\n",
    "noise = np.random.normal(0, 0.2, X.shape)\n",
    "y = np.sin(X) + noise\n",
    "\n",
    "# first layer of neurons\n",
    "\n",
    "def create_layer(n_inputs, n_neurons):\n",
    "    # Weights and biases\n",
    "    W = tf.Variable(tf.random_normal([n_inputs, n_neurons]))\n",
    "    b = tf.Variable(tf.zeros([n_neurons]))\n",
    "    # Weights and biases\n",
    "    return W, b\n",
    "\n",
    "# load training data\n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "# load testing data\n",
    "X_test = X[1000:]\n",
    "y_test = y[1000:]\n",
    "\n",
    "# create the model\n",
    "n_neurons = 10\n",
    "n_inputs = 1\n",
    "n_outputs = 1\n",
    "\n",
    "# create the first layer\n",
    "W1, b1 = create_layer(n_inputs, n_neurons)\n",
    "# create the second layer\n",
    "W2, b2 = create_layer(n_neurons, n_outputs)\n",
    "\n",
    "# create the model\n",
    "def model(X, W1, b1, W2, b2):\n",
    "    # first layer\n",
    "    l1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    # second layer\n",
    "    l2 = tf.matmul(l1, W2) + b2\n",
    "    return l2\n",
    "\n",
    "# training the model\n",
    "# create the placeholder for the input\n",
    "X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "# create the placeholder for the output\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "# create the model\n",
    "l2 = model(X, W1, b1, W2, b2)\n",
    "# create the cost function\n",
    "cost = tf.reduce_mean(tf.square(l2 - y))\n",
    "# create the optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# create the training operation\n",
    "train_op = optimizer.minimize(cost)\n",
    "# create the session\n",
    "sess = tf.Session()\n",
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "# train the model\n",
    "for i in range(100):\n",
    "    _, cost_val = sess.run([train_op, cost], feed_dict={X: X_train, y: y_train})\n",
    "    if i % 10 == 0:\n",
    "        # add a layer to the model between the output layer and last layer\n",
    "        W1, b1 = create_layer(n_neurons, n_neurons)\n",
    "        W2, b2 = create_layer(n_neurons, n_outputs)\n",
    "        # transfer the old layers\n",
    "        sess.run(tf.assign(W1, W1))\n",
    "        sess.run(tf.assign(b1, b1))\n",
    "        sess.run(tf.assign(W2, W2))\n",
    "        sess.run(tf.assign(b2, b2))\n",
    "        # train the model\n",
    "        print(cost_val)\n",
    "# predict the model\n",
    "pred = sess.run(l2, feed_dict={X: X_test})\n",
    "# plot the results\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, pred, 'r')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
