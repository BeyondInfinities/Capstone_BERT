{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import json\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music = pd.read_csv(\"Results/music_variance.csv\")\n",
    "# plot the histrogram of the data\n",
    "plt.hist(df_music['0'], bins=200)\n",
    "\n",
    "\n",
    "# calculate the mean and standard deviation of the data\n",
    "mean = np.mean(df_music['0'])\n",
    "std = np.std(df_music['0'])\n",
    "# plot the mean and standard deviation on the histogram\n",
    "plt.axvline(mean, color='b', linestyle='dotted', linewidth=2, alpha=0.5)\n",
    "\n",
    "!pip3 install scipy\n",
    "# fit an exponential distribution to the data:\n",
    "from scipy.stats import expon\n",
    "\n",
    "# fit an exponential distribution to the data:\n",
    "param = expon.fit(df_music['0'])\n",
    "\n",
    "# now, param[0] and param[1] are the mean and \n",
    "# the standard deviation of the fitted distribution\n",
    "x = np.linspace(0,1,100)\n",
    "# fitted distribution\n",
    "pdf_fitted = expon.pdf(x,loc=param[0],scale=param[1]) * 10\n",
    "# original distribution\n",
    "pdf = expon.pdf(x) \n",
    "\n",
    "\n",
    "plt.plot(x,pdf_fitted,'r-',x,pdf,'grey', alpha=0.5)\n",
    "plt.title(f\"Distribution of Genre (Music) Variance by attribute \\n Mean: {mean:.2f} Std: {std:.2f}\")\n",
    "plt.xlabel('Variance')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plot(ax, file):\n",
    "    df = pd.read_csv(f\"Results/{file}.csv\")\n",
    "    # plot the histrogram of the data\n",
    "    ax.hist(df['0'], bins=50)\n",
    "\n",
    "\n",
    "    # calculate the mean and standard deviation of the data\n",
    "    mean = np.mean(df['0'])\n",
    "    std = np.std(df['0'])\n",
    "    # plot the mean and standard deviation on the histogram\n",
    "    ax.axvline(mean, color='b', linestyle='dotted', linewidth=2, alpha=0.5)\n",
    "\n",
    "    # fit an exponential distribution to the data:\n",
    "    from scipy.stats import expon\n",
    "\n",
    "    # fit an exponential distribution to the data:\n",
    "    param = expon.fit(df['0'])\n",
    "\n",
    "    # now, param[0] and param[1] are the mean and \n",
    "    # the standard deviation of the fitted distribution\n",
    "    x = np.linspace(0,np.max(df['0']),100)\n",
    "    # fitted distribution\n",
    "    pdf_fitted = expon.pdf(x,loc=param[0],scale=param[1]) * 10\n",
    "    # original distribution\n",
    "    pdf = expon.pdf(x) \n",
    "\n",
    "    ax.plot(x,pdf_fitted,'r-',x,pdf,'grey', alpha=0.5)\n",
    "    fontdict = {'fontsize': 8, 'fontweight': 'medium'}\n",
    "    ax.set_title(f\"Distribution of {file} bias Variance by attribute \\n Mean: {mean:.2f} Std: {std:.2f}\", fontdict=fontdict)\n",
    "    ax.set_xlabel('Variance', fontdict=fontdict)\n",
    "    ax.set_ylabel('Count', fontdict=fontdict)\n",
    "    return ax, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10,10))\n",
    "# store the dfs in a list\n",
    "dfs = {}\n",
    "for i, file in enumerate([\"country_variance\", \"religion_variance\", \"music_variance\", \"dish_variance\"]):\n",
    "    ax[i//2, i%2], df = result_plot(ax[i//2, i%2], file)\n",
    "    dfs[file] = df\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the columns of the dataframe\n",
    "dfs[\"country_variance\"].columns = [\"attribute\", \"variance\"]\n",
    "dfs[\"religion_variance\"].columns = [\"attribute\", \"variance\"]\n",
    "dfs[\"music_variance\"].columns = [\"attribute\", \"variance\"]\n",
    "dfs[\"dish_variance\"].columns = [\"attribute\", \"variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weigh the attributes by their sentiment score using nltk\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# get the sentiment score of each attribute\n",
    "def get_sentiment_score(attribute):\n",
    "    \"\"\"\n",
    "    :param attribute: the attribute of the user\n",
    "    :return: the sentiment score of the attribute\n",
    "    \"\"\"\n",
    "    score = sid.polarity_scores(attribute)\n",
    "    return score['compound']\n",
    "\n",
    "# add the sentiment score to the dataframe\n",
    "def add_modified_score(df):\n",
    "    \"\"\"\n",
    "    :param df: the dataframe to add the modified score to\n",
    "    :return: the dataframe with the modified score \n",
    "    \"\"\"\n",
    "    df['sentiment_score'] = df['attribute'].apply(get_sentiment_score).abs()\n",
    "    df['modified_score'] = df['variance'] * df['sentiment_score']\n",
    "    return df\n",
    "\n",
    "# apply the function to each dataframe\n",
    "for key, df in dfs.items():\n",
    "    dfs[key] = add_modified_score(df)\n",
    "\n",
    "# plot the modified score\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20,15))\n",
    "for i, file in enumerate([\"country_variance\", \"religion_variance\", \"music_variance\", \"dish_variance\"]):\n",
    "    ax[i//2, i%2].hist(dfs[file]['modified_score'], bins=50)\n",
    "    ax[i//2, i%2].set_title(f\"Distribution of {file} bias Variance by attribute \\n Mean: {np.mean(dfs[file]['modified_score']):.2f} Std: {np.std(dfs[file]['modified_score']):.2f}\")\n",
    "    ax[i//2, i%2].set_xlabel('Variance')\n",
    "    ax[i//2, i%2].set_ylabel('Count')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are a lot of zero values, this represent neutral adjectives and should be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with no adjectives with 0 sentiment score\n",
    "dfs_no_zero = {}\n",
    "for key, df in dfs.items():\n",
    "    dfs_no_zero[key] = df[df['sentiment_score'] != 0]\n",
    "\n",
    "# plot the modified score\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20,15))\n",
    "for i, file in enumerate([\"country_variance\", \"religion_variance\", \"music_variance\", \"dish_variance\"]):\n",
    "    ax[i//2, i%2].hist(dfs_no_zero[file]['modified_score'], bins=50)\n",
    "    ax[i//2, i%2].set_title(f\"Distribution of {file} bias Variance by attribute \\n Mean: {np.mean(dfs_no_zero[file]['modified_score']):.2f} Std: {np.std(dfs_no_zero[file]['modified_score']):.2f}\")\n",
    "    ax[i//2, i%2].set_xlabel('Variance')\n",
    "    ax[i//2, i%2].set_ylabel('Count')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a 2d heatmap of the 2d interaction bias\n",
    "\n",
    "# Load the data\n",
    "cg_2 = json.load(open('Interaction_results/CG_score_2.json'))\n",
    "mcg_2 = json.load(open('Interaction_results/modified_cg_score_2.json'))\n",
    "\n",
    "# convert all keys into tuple seprated by comma\n",
    "cg_2 = {tuple(k.split(',')): v for k, v in cg_2.items()}\n",
    "mcg_2 = {tuple(k.split(',')): v for k, v in mcg_2.items()}\n",
    "\n",
    "# assign numbers to each category from the keys in the dictionary\n",
    "categories = set()\n",
    "for k in cg_2.keys():\n",
    "    categories.add(k[0])\n",
    "    categories.add(k[1])\n",
    "categories = list(categories)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "# change the background within the subplots\n",
    "for ax in axs:\n",
    "    ax.patch.set_facecolor('lightgrey')\n",
    "\n",
    "# create a dataframe with the values\n",
    "for i, cg in enumerate([cg_2, mcg_2]):\n",
    "    ax = axs[i]\n",
    "    df = pd.DataFrame(columns=categories, index=categories)\n",
    "    for k, v in cg.items():\n",
    "        key = (k[0], k[1]) if categories.index(k[0]) > categories.index(k[1]) else (k[1], k[0])\n",
    "        df.loc[key] = v\n",
    "    df = df.fillna(-1)\n",
    "    sns.heatmap(df, annot=True, fmt='.2f', cmap='Blues', ax=ax, mask = df == -1)\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_title(f'{\"M\" if i==1 else \"\"}CBS between 2 characteristics')\n",
    "\n",
    "\n",
    "fig.suptitle('The modified and unmodified CBS between 2 characteristics', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcg_2.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 2d heatmap of the 2d interaction bias for modified CG\n",
    "dfc = pd.DataFrame(columns=categories, index=categories)\n",
    "\n",
    "for k, v in mcg_2.items():\n",
    "    # rearrange so that the key is always in the same order\n",
    "    # preference order is given by the categories list\n",
    "    key = (k[0], k[1]) if categories.index(k[0]) > categories.index(k[1]) else (k[1], k[0])\n",
    "    dfc.loc[key] = v\n",
    "dfc = dfc.fillna(-1)\n",
    "\n",
    "# plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# sns.heatmap(dfc, annot=True, fmt='.2f', cmap='Blues', ax=ax)\n",
    "\n",
    "# we need to grey out the cells that are not in the original dataset\n",
    "# by using mask\n",
    "mask = dfc == -1\n",
    "ax = sns.heatmap(dfc, annot=True, fmt='.2f', cmap='Blues', mask=mask)\n",
    "\n",
    "# reverse the x axis to make it more readable\n",
    "ax.invert_xaxis()\n",
    "# remove duplicate combination of categories\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.set_title('MCBS between 2 characteristics')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_3 = json.load(open('Interaction_results/CG_score_3.json'))\n",
    "mcg_3 = json.load(open('Interaction_results/modified_cg_score_3.json'))\n",
    "\n",
    "# convert all keys into tuple seprated by comma\n",
    "cg_3 = {tuple(k.split(',')): v for k, v in cg_3.items()}\n",
    "mcg_3 = {tuple(k.split(',')): v for k, v in mcg_3.items()}\n",
    "\n",
    "# we will use the same number of categories as before\n",
    "# We have to find a way to represent 4 d data \n",
    "\n",
    "\n",
    "# representation one lattice of 3d data\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "# convert the tuple keys into a list of points in 3d space using the categories\n",
    "# as the coordinates\n",
    "\n",
    "# create a list of points\n",
    "cg3_points = []\n",
    "for k in cg_3.keys():\n",
    "    cg3_points.append([categories.index(k[0]), categories.index(k[1]), categories.index(k[2]), cg_3[k]])\n",
    "\n",
    "mcg_3_points = []\n",
    "for k in mcg_3.keys():\n",
    "    mcg_3_points.append([categories.index(k[0]), categories.index(k[1]), categories.index(k[2]), mcg_3[k]])\n",
    "\n",
    "\n",
    "cg3_points, mcg_3_points = np.array(cg3_points), np.array(mcg_3_points)\n",
    "\n",
    "img = ax.scatter(cg3_points[:,0], cg3_points[:,1],cg3_points[:,2] , c=cg3_points[:,3], cmap=plt.viridis())\n",
    "fig.colorbar(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of the 3d interaction bias by keeping one category fixed\n",
    "fig, ax = plt.subplots(3,2, figsize=(20,10))\n",
    "ax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\n",
    "ax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\n",
    "ax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\n",
    "ax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\n",
    "ax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n",
    "ax = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "for i, fixed_category in enumerate(categories):\n",
    "    cur_ax = ax[i]\n",
    "    fix_categories = list(set(categories) - set([fixed_category]))\n",
    "    df = pd.DataFrame(columns=fix_categories, index=fix_categories)\n",
    "    for k, v in cg_3.items():\n",
    "        if fixed_category in k:\n",
    "            # find the index of the fixed category\n",
    "            other_categories = list(k)\n",
    "            idx =other_categories.index(fixed_category)\n",
    "            other_categories.pop(idx)\n",
    "            # rearrange the key so that it is always in the same order\n",
    "            key = (other_categories[0], other_categories[1]) if fix_categories.index(other_categories[0]) > fix_categories.index(other_categories[1]) else (other_categories[1], other_categories[0])\n",
    "            df.loc[key] = v\n",
    "    df = df.fillna(-1)\n",
    "    mask = df == -1\n",
    "    sns.heatmap(df, annot=True, fmt='.3f', cmap='Blues', ax=cur_ax, mask=mask)\n",
    "    cur_ax.invert_xaxis()\n",
    "    cur_ax.set_title('{} fixed'.format(fixed_category))\n",
    "\n",
    "# figure title\n",
    "fig.suptitle('CBS between 3 characteristics', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of the 3d interaction bias by keeping one category fixed\n",
    "fig, ax = plt.subplots(3,2, figsize=(20,10))\n",
    "ax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\n",
    "ax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\n",
    "ax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\n",
    "ax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\n",
    "ax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n",
    "ax = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "for i, fixed_category in enumerate(categories):\n",
    "    cur_ax = ax[i]\n",
    "    fix_categories = list(set(categories) - set([fixed_category]))\n",
    "    df = pd.DataFrame(columns=fix_categories, index=fix_categories)\n",
    "    for k, v in mcg_3.items():\n",
    "        if fixed_category in k:\n",
    "            # find the index of the fixed category\n",
    "            other_categories = list(k)\n",
    "            idx =other_categories.index(fixed_category)\n",
    "            other_categories.pop(idx)\n",
    "            # rearrange the key so that it is always in the same order\n",
    "            key = (other_categories[0], other_categories[1]) if fix_categories.index(other_categories[0]) > fix_categories.index(other_categories[1]) else (other_categories[1], other_categories[0])\n",
    "            df.loc[key] = v\n",
    "    df = df.fillna(-1)\n",
    "    mask = df == -1\n",
    "    sns.heatmap(df, annot=True, fmt='.3f', cmap='Blues', ax=cur_ax, mask=mask)\n",
    "    cur_ax.invert_xaxis()\n",
    "    cur_ax.set_title('{} fixed'.format(fixed_category))\n",
    "\n",
    "fig.suptitle('MCBS between 3 characteristics', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_4 = json.load(open('Interaction_results/CG_score_4.json'))\n",
    "mcg_4 = json.load(open('Interaction_results/modified_cg_score_4.json'))\n",
    "\n",
    "# convert all keys into tuple seprated by comma\n",
    "cg_4 = {tuple(k.split(',')): v for k, v in cg_4.items()}\n",
    "mcg_4 = {tuple(k.split(',')): v for k, v in mcg_4.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a single bar graph of the 4d bias by mentioning the missing category\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(12, 7))\n",
    "\n",
    "for i in range(2):\n",
    "    x, y = [], []\n",
    "    for missing_category in categories:\n",
    "        x.append(missing_category)\n",
    "        # find the tuple with the missing category\n",
    "        score = mcg_4 if i == 0 else cg_4\n",
    "        for k, v in score.items():\n",
    "            if missing_category not in k:\n",
    "                y.append(v)\n",
    "                break\n",
    "\n",
    "    # use standard style for plt\n",
    "    plt.style.use('default')\n",
    "\n",
    "    ax[i].bar(x, y)\n",
    "    ax[i].set_title(f'{\"M\" if i ==0 else \"\"}CBS between 4 characteristics')\n",
    "    ax[i].set_xlabel('Missing Category')\n",
    "    ax[i].set_ylabel(f'{\"M\" if i ==0 else \"\"}CBS')\n",
    "\n",
    "fig.suptitle('CBS and MCBS between 4 characteristics', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Interactions\n",
    "There is a single number between that represents this bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_5 = json.load(open('Interaction_results/CG_score_5.json'))\n",
    "mcg_5 = json.load(open('Interaction_results/modified_cg_score_5.json'))\n",
    "\n",
    "print('cg_5', cg_5)\n",
    "print('mcg_5', mcg_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seprating positive and negative attribute interaction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# get the sentiment score of each attribute\n",
    "def get_sentiment_score(attribute):\n",
    "    score = sid.polarity_scores(attribute)\n",
    "    return score['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_bias(filename):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(f\"Interaction_results/{filename}\")\n",
    "    # columns are Adjective,Characteristics,Values,Probs,Probs_base\n",
    "    # find all positive attributes and remove the negative ones\n",
    "    for i, row in df.iterrows():\n",
    "        if get_sentiment_score(row['Adjective']) < 0:\n",
    "            df.drop(i, inplace=True)\n",
    "    \n",
    "    # find the bias of the positive attributes\n",
    "    # group by the adjective then characteristics\n",
    "    groups =  df.groupby(['Adjective', 'Characteristics'] )\n",
    "\n",
    "    new_df = pd.DataFrame(columns=['Adjective', 'Characteristics', 'Variance'])\n",
    "    for name, group in groups:\n",
    "        # calculate the variance of log(probs)-log(probs_base) for every adjective\n",
    "        variance = np.var(group['Probs'] - group['Probs_base'])\n",
    "        new_df = new_df.append({'Adjective': name[0], 'Characteristics': name[1], 'Variance': variance}, ignore_index=True)\n",
    "    \n",
    "    # mean the variance for every characteristic\n",
    "    groups = new_df.groupby(['Characteristics'])\n",
    "    new_df = pd.DataFrame(columns=['Characteristics', 'Variance'])\n",
    "    for name, group in groups:\n",
    "        # calculate the variance of log(probs)-log(probs_base) for every adjective\n",
    "        variance = np.mean(group['Variance'])\n",
    "        new_df = new_df.append({'Characteristics': name, 'Variance': variance}, ignore_index=True)\n",
    "    \n",
    "    return new_df\n",
    "        \n",
    "\n",
    "\n",
    "positive = positive_bias('CG_score_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive['Characteristics'] = positive['Characteristics'].apply(lambda x: x[1:-1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 2d heatmap of the bias by characteristics\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "categories = set([ a for a in positive['Characteristics']])\n",
    "df = pd.DataFrame(columns=categories, index=categories)\n",
    "for i, row in positive.iterrows():\n",
    "    for c in row['Characteristics']:\n",
    "        df.loc[row['Characteristics'][0], row['Characteristics'][1]] = row['Variance']\n",
    "\n",
    "sns.heatmap(df, annot=True, fmt='.3f', cmap='Blues', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ff4a94ddf0fc1c58829e0067cbc3216f8106c09a77337d8a03f9933a8736174"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
