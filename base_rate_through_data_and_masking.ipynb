{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem with base rates\n",
    "Base rates are the rates at which the model in question predicts different classes for **neutral** sentences. A neutral sentence is a sentence that does not imply any bias (bias differs by context). For instance, \"People from [MASK] eat, drink, and sleep\". This is a neutral statement in a sense that the missing keyword does not effect the meaning of the sentence, as all humans need to eat,drink and sleep. Hence, if the missing keyword is \"China\", with probability of 0.1 and \"Lithuania\" with probability 0.01 the difference in rates is not because the model is biased but rather because the model has just seen china more often than Lithuania. Hence, one can derive base rates from the data or using masking tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import textstat\n",
    "import requests\n",
    "from unittest import result\n",
    "import json\n",
    "# MASK\n",
    "unmasker = pipeline('fill-mask', model='bert-large-cased-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unmasker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cc/rg95d6md72g_vqjj1ln7b5lc0000gn/T/ipykernel_36324/1853324545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mbase_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneutral_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbase_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unmasker' is not defined"
     ]
    }
   ],
   "source": [
    "neutral_sentences = [\n",
    "    \"[MASK] is name of a country.\",\n",
    "    \"I am a country named [MASK].\",\n",
    "    \"[MASK] is a country\",\n",
    "    \"Name of a country is [MASK].\",\n",
    "    \"Name a country. [MASK] is a country.\",\n",
    "    \"[MASK] is a country on earth.\",\n",
    "    \"Name a country. [MASK] is a country on earth.\",\n",
    "    \"You are a country named [MASK].\",\n",
    "    \"They are from a country named [MASK].\",\n",
    "]\n",
    "from collections import defaultdict\n",
    "base_rate = defaultdict(float)\n",
    "for sentance in neutral_sentences:\n",
    "    result = unmasker(sentance)\n",
    "    for j in result:\n",
    "        base_rate[j['token_str'].lower().strip()] += j['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {'afghanistan': 0.26134091801941395, 'this': 0.20562006533145905, 'it': 0.23169870488345623, 'country': 0.028564760461449623, 'flag': 0.026396427303552628, 'america': 0.04062959924340248, 'russia': 0.05847242288291454, 'romania': 0.025461118668317795, 'germany': 0.04398747347295284, 'hungary': 0.021298104897141457, 'india': 0.11685409396886826, 'australia': 0.14475287683308125, 'azerbaijan': 0.05705759860575199, 'latin': 0.046762265264987946, 'variable': 0.0466257780790329, 'english': 0.040855757892131805, 'optional': 0.0372978113591671, 'international': 0.03460304066538811, 'ireland': 0.06681019067764282, 'turkey': 0.05857176519930363, 'italy': 0.025413205847144127, 'there': 0.4495214521884918, 'name': 0.10852814465761185, 'that': 0.057182133197784424, 'mongolia': 0.024394305422902107, 'israel': 0.07051292806863785, 'albania': 0.046807706356048584, 'armenia': 0.03200598061084747})\n"
     ]
    }
   ],
   "source": [
    "print(base_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/homebrew/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Using next sentence prediction to calculate the base rate\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "import pandas as pd\n",
    "countries = list(pd.read_csv('demo_data.csv')['country'].unique())\n",
    "base_rate_from_NSP = defaultdict(float)\n",
    "for country in countries:\n",
    "    text = (\"Name a country.\")\n",
    "    text2 = (f\"{country} is a country.\")\n",
    "    inputs = tokenizer(text, text2, return_tensors='pt')\n",
    "    labels = torch.LongTensor([1])\n",
    "    outputs = model(**inputs, labels=labels)\n",
    "    # calculate the output loss\n",
    "    # 1 represents the next sentence is the second sentence\n",
    "    base_rate_from_NSP[country] = outputs.loss.item()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
